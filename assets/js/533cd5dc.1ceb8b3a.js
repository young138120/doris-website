"use strict";(self.webpackChunkdoris_website=self.webpackChunkdoris_website||[]).push([["295705"],{216896:function(e,n,i){i.r(n),i.d(n,{metadata:()=>r,contentTitle:()=>a,default:()=>u,assets:()=>c,toc:()=>l,frontMatter:()=>o});var r=JSON.parse('{"id":"query-acceleration/tuning/query-profile","title":"Query Profile","description":"\x3c!--","source":"@site/docs/query-acceleration/tuning/query-profile.md","sourceDirName":"query-acceleration/tuning","slug":"/query-acceleration/tuning/query-profile","permalink":"/docs/dev/query-acceleration/tuning/query-profile","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"Query Profile","language":"en"},"sidebar":"docs","previous":{"title":"Overview","permalink":"/docs/dev/query-acceleration/tuning/overview"},"next":{"title":"Optimizing Table Schema Design","permalink":"/docs/dev/query-acceleration/tuning/tuning-plan/optimizing-table-schema"}}'),s=i("785893"),t=i("250065");let o={title:"Query Profile",language:"en"},a=void 0,c={},l=[{value:"Identifying Slow Queries with QueryID",id:"identifying-slow-queries-with-queryid",level:2},{value:"Analyzing Query Performance using Profile",id:"analyzing-query-performance-using-profile",level:2},{value:"Profile File Structure",id:"profile-file-structure",level:3},{value:"Analyzing BE Execution with Merged Profile",id:"analyzing-be-execution-with-merged-profile",level:3},{value:"Analyzing BE Execution with Execution Profile",id:"analyzing-be-execution-with-execution-profile",level:3},{value:"Analyzing PipelineTask Execution Times",id:"analyzing-pipelinetask-execution-times",level:3},{value:"Troubleshooting Steps for Performance Issues",id:"troubleshooting-steps-for-performance-issues",level:2},{value:"1 Identify Operator Execution Issues",id:"1-identify-operator-execution-issues",level:3},{value:"2 Identify Data Skew Issues",id:"2-identify-data-skew-issues",level:3},{value:"3 Identify High RPC Latency Issues",id:"3-identify-high-rpc-latency-issues",level:3},{value:"4 Identify High Cluster Load Issues",id:"4-identify-high-cluster-load-issues",level:3}];function d(e){let n={admonition:"admonition",code:"code",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.a)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.p,{children:"When executing queries in Doris and encountering performance issues, it is recommended to conduct a further analysis. This document provides a comprehensive guide on how to analyze query performance in Doris."}),"\n",(0,s.jsx)(n.p,{children:"In Doris, since profile collection introduces overhead, it is disabled by default. To perform query performance analysis, you first need to enable it by executing the following command in the MySQL Client:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"set enable_profile = true;\n"})}),"\n",(0,s.jsx)(n.h2,{id:"identifying-slow-queries-with-queryid",children:"Identifying Slow Queries with QueryID"}),"\n",(0,s.jsxs)(n.p,{children:["The first step in analyzing query performance is to obtain the QueryID of the query in question. You can find the QueryID in the ",(0,s.jsx)(n.code,{children:"fe/log/fe.audit.log"})," log file."]}),"\n",(0,s.jsxs)(n.p,{children:["For example, let's consider a specific query from TPC-H. By examining the log information, we can identify the QueryID as ",(0,s.jsx)(n.code,{children:"QueryId=704185c15570441b-98ad0634c88584f0"}),"."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-json",children:'2024-08-20 14:37:23,729 [query] IClient=127.0.0.1:33570|User=root|Ctl=internal Db=regression_test_tpch_sf0_1_p1I|State=EOF|ErrorCode=0|ErrorMessage=|Time(ms)=153|ScanBytes=0|ScanRows=0|ReturnRows=1|StmtId=1191|QueryId=704185c15570441b-98ad0634c88584f0|IsQuery=true|isNereids=true|feIp=168.45.0.1|StmtType=SELECT|Stmt=SELECT sum(l_extendedprice) / 7.0 AS avg_yearly FROM lineitem, part WHERE p_partkey = l_partkey AND p_brand_ "Brand#23" AND p_container = "MED BOX" AND l_quantity < ( SELECT 0.2*avg(l_quantity) FROM lineitem WHERE l_partkey= p_partkey) |CpuTimeMS=401ShuffleSendBytes=0|ShuffleSendRows=0|SqlHash=\u0435\u04412e14fac69b9711dc305e218f1e94b8|peakMemoryBytes=33792|SqlDigest=|cloudClusterName=UNKNOWN|TraceId=|WcorkloadGroup=normal|FuzzyVariables=|scanBytesFromLocalStorage=0|scanBytesFromRemoteStorage=0\n'})}),"\n",(0,s.jsx)(n.h2,{id:"analyzing-query-performance-using-profile",children:"Analyzing Query Performance using Profile"}),"\n",(0,s.jsxs)(n.p,{children:["After obtaining the QueryID, you can retrieve the Profile details by accessing the corresponding FE's WebUI. For example, by visiting the link ",(0,s.jsx)(n.code,{children:"http://{fe_ip}:{http_port}/QueryProfile/704185c15570441b-98ad0634c88584f0"}),", you can view the Profile information. For more detailed information, you can download the ",(0,s.jsx)(n.code,{children:"profile_704185c15570441b-98ad0634c88584f0.txt"})," file."]}),"\n",(0,s.jsx)(n.h3,{id:"profile-file-structure",children:"Profile File Structure"}),"\n",(0,s.jsx)(n.p,{children:"The Profile file consists of several main sections:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Basic Query Information: Includes ID, timestamp, database, etc."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"SQL Statement and Execution Plan."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"FE Time Breakdown (Plan Time, Schedule Time, etc.)."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"BE Operator Execution Times: Breakdown of each Operator's execution time (Merged Profile, Execution Profile, and each PipelineTask within Execution Profile)."}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"In slow queries, the bottlenecks usually lie in the BE execution process. The following sections will focus on analyzing this part."}),"\n",(0,s.jsx)(n.h3,{id:"analyzing-be-execution-with-merged-profile",children:"Analyzing BE Execution with Merged Profile"}),"\n",(0,s.jsx)(n.p,{children:"Doris provides an aggregated view of Operator performance in the Merged Profile to help users identify performance bottlenecks more accurately."}),"\n",(0,s.jsxs)(n.p,{children:["Taking ",(0,s.jsx)(n.code,{children:"EXCHANGE_OPERATOR"})," (id=4) as an example:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-Python",children:"EXCHANGE_OPERATOR  (id=4):\n    -  BlocksProduced:  sum  0,  avg  0,  max  0,  min  0\n    -  CloseTime:  avg  34.133us,  max  38.287us,  min  29.979us\n    -  ExecTime:  avg  700.357us,  max  706.351us,  min  694.364us\n    -  InitTime:  avg  648.104us,  max  648.604us,  min  647.605us\n    -  MemoryUsage:  sum  ,  avg  ,  max  ,  min  \n        -  PeakMemoryUsage:  sum  0.00  ,  avg  0.00  ,  max  0.00  ,  min  0.00  \n    -  OpenTime:  avg  4.541us,  max  5.943us,  min  3.139us\n    -  ProjectionTime:  avg  0ns,  max  0ns,  min  0ns\n    -  RowsProduced:  sum  0,  avg  0,  max  0,  min  0\n    -  WaitForDependencyTime:  avg  0ns,  max  0ns,  min  0ns\n        -  WaitForData0:  avg  9.434ms,  max  9.476ms,  min  9.391ms\n"})}),"\n",(0,s.jsx)(n.p,{children:"The Merged Profile consolidates core metrics for each Operator:"}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Metric Name"}),(0,s.jsx)(n.th,{children:"Description"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"BlocksProduced"}),(0,s.jsx)(n.td,{children:"Number of Data Blocks produced"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"CloseTime"}),(0,s.jsx)(n.td,{children:"Time taken by the Operator during Close"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"ExecTime"}),(0,s.jsx)(n.td,{children:"Total execution time of the Operator"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"InitTime"}),(0,s.jsx)(n.td,{children:"Time taken by the Operator during Init"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"MemoryUsage"}),(0,s.jsx)(n.td,{children:"Memory usage during Operator execution"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"OpenTime"}),(0,s.jsx)(n.td,{children:"Time taken by the Operator during Open"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"ProjectionTime"}),(0,s.jsx)(n.td,{children:"Time taken during Projection"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"RowsProduced"}),(0,s.jsx)(n.td,{children:"Number of rows returned by the Operator"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"WaitForDependencyTime"}),(0,s.jsx)(n.td,{children:"Time spent waiting for dependencies"})]})]})]}),"\n",(0,s.jsx)(n.p,{children:"In Doris, each Operator executes concurrently based on user-defined concurrency levels. Therefore, the Merged Profile calculates Max, Avg, and Min values for each metric across all concurrent executions."}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"WaitForDependencyTime"})," metric varies for different Operators depending on their execution dependencies. For example, in the case of EXCHANGE_OPERATOR, it represents the time spent waiting for data from upstream Operators via RPC."]}),"\n",(0,s.jsx)(n.h3,{id:"analyzing-be-execution-with-execution-profile",children:"Analyzing BE Execution with Execution Profile"}),"\n",(0,s.jsx)(n.p,{children:"Unlike the Merged Profile, the Execution Profile provides detailed metrics for a specific concurrent execution."}),"\n",(0,s.jsxs)(n.p,{children:["Again, taking ",(0,s.jsx)(n.code,{children:"EXCHANGE_OPERATOR"})," (id=4) as an example:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-Python",children:"EXCHANGE_OPERATOR  (id=4):(ExecTime:  706.351us)\n      -  BlocksProduced:  0\n      -  CloseTime:  38.287us\n      -  DataArrivalWaitTime:  0ns\n      -  DecompressBytes:  0.00  \n      -  DecompressTime:  0ns\n      -  DeserializeRowBatchTimer:  0ns\n      -  ExecTime:  706.351us\n      -  FirstBatchArrivalWaitTime:  0ns\n      -  InitTime:  647.605us\n      -  LocalBytesReceived:  0.00  \n      -  MemoryUsage:  \n          -  PeakMemoryUsage:  0.00  \n      -  OpenTime:  5.943us\n      -  ProjectionTime:  0ns\n      -  RemoteBytesReceived:  0.00  \n      -  RowsProduced:  0\n      -  SendersBlockedTotalTimer(*):  0ns\n      -  WaitForDependencyTime:  0ns\n          -  WaitForData0:  9.476ms\n"})}),"\n",(0,s.jsx)(n.admonition,{title:"Note",type:"info",children:(0,s.jsxs)(n.p,{children:["In this Profile, ",(0,s.jsx)(n.code,{children:"LocalBytesReceived"})," is unique to the Exchange Operator and not present in other Operators, hence it's not included in the Merged Profile."]})}),"\n",(0,s.jsx)(n.h3,{id:"analyzing-pipelinetask-execution-times",children:"Analyzing PipelineTask Execution Times"}),"\n",(0,s.jsx)(n.p,{children:"In Doris, a PipelineTask consists of multiple Operators. When analyzing the execution time of a PipelineTask, focus on the following aspects:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"ExecuteTime: Represents the actual execution time of the entire PipelineTask, roughly equal to the sum of ExecTime for all Operators within the Task."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["WaitWorkerTime: Represents the time the Task waits for an available Worker to execute. When a task is in the ",(0,s.jsx)(n.code,{children:"runnable"})," state, it waits for an idle worker to execute, which depends on cluster load."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Wait Time for Dependencies: A Task can execute when all its Operators' dependencies are met. The wait time for dependencies is the sum of these wait times."}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Taking one of the tasks from the previous example:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-Python",children:"PipelineTask  (index=1):(ExecTime:  4.773ms)\n  -  ExecuteTime:  1.656ms\n      -  CloseTime:  90.402us\n      -  GetBlockTime:  11.235us\n      -  OpenTime:  1.448ms\n      -  PrepareTime:  1.555ms\n      -  SinkTime:  14.228us\n  -  WaitWorkerTime:  63.868us\n    DATA_STREAM_SINK_OPERATOR  (id=8,dst_id=8):(ExecTime:  1.688ms)\n      -  WaitForDependencyTime:  0ns\n          -  WaitForBroadcastBuffer:  0ns\n          -  WaitForRpcBufferQueue:  0ns\n    AGGREGATION_OPERATOR  (id=7  ,  nereids_id=648):(ExecTime:  398.12us)\n      -  WaitForDependency[AGGREGATION_OPERATOR_DEPENDENCY]Time:  10.495ms\n"})}),"\n",(0,s.jsxs)(n.p,{children:["This task includes ",(0,s.jsx)(n.code,{children:"DATA_STREAM_SINK_OPERATOR"})," and ",(0,s.jsx)(n.code,{children:"AGGREGATION_OPERATOR"}),". Among them:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"DATA_STREAM_SINK_OPERATOR"})," has two dependencies: ",(0,s.jsx)(n.code,{children:"WaitForBroadcastBuffer"})," and ",(0,s.jsx)(n.code,{children:"WaitForRpcBufferQueue"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"AGGREGATION_OPERATOR"})," has one dependency: ",(0,s.jsx)(n.code,{children:"AGGREGATION_OPERATOR_DEPENDENCY"}),"."]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"The time distribution for this task is:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"ExecuteTime: 1.656ms (approximately the sum of ExecTime for both Operators)"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"WaitWorkerTime: 63.868us (indicating low cluster load as the Task executed immediately after becoming runnable)"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["Wait Time for Dependencies: 10.495ms (sum of wait times for all dependencies, including ",(0,s.jsx)(n.code,{children:"WaitForBroadcastBuffer"}),", ",(0,s.jsx)(n.code,{children:"WaitForRpcBufferQueue"}),", and ",(0,s.jsx)(n.code,{children:"WaitForDependency[AGGREGATION_OPERATOR_DEPENDENCY]"}),")"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"troubleshooting-steps-for-performance-issues",children:"Troubleshooting Steps for Performance Issues"}),"\n",(0,s.jsx)(n.p,{children:"When troubleshooting performance issues in Doris, follow these four steps:"}),"\n",(0,s.jsx)(n.h3,{id:"1-identify-operator-execution-issues",children:"1 Identify Operator Execution Issues"}),"\n",(0,s.jsxs)(n.p,{children:["Slow Operator execution is a common issue in production environments. To locate these issues, analyze the ",(0,s.jsx)(n.code,{children:"ExecTime"})," and ",(0,s.jsx)(n.code,{children:"WaitForDependencyTime"})," for each Operator in the Merged Profile's Plan Tree."]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["If ",(0,s.jsx)(n.code,{children:"ExecTime"})," is high, it indicates an Operator performance issue, which could stem from the Operator's inherent performance or an unoptimized execution plan."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["If ",(0,s.jsx)(n.code,{children:"ExecTime"})," is low but ",(0,s.jsx)(n.code,{children:"WaitForDependencyTime"})," is high, the bottleneck likely lies upstream and requires further investigation along the Plan Tree."]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"2-identify-data-skew-issues",children:"2 Identify Data Skew Issues"}),"\n",(0,s.jsxs)(n.p,{children:["When troubleshooting Operator performance, observe significant differences between minimum and maximum ",(0,s.jsx)(n.code,{children:"ExecTime"})," values for an Operator. If present, check if there are also significant differences in the amount of data processed (",(0,s.jsx)(n.code,{children:"RowsProduced"}),"). If so, this indicates data skew."]}),"\n",(0,s.jsx)(n.h3,{id:"3-identify-high-rpc-latency-issues",children:"3 Identify High RPC Latency Issues"}),"\n",(0,s.jsxs)(n.p,{children:["If no slow Operators are identified after traversing the entire Plan Tree, investigate RPC latency issues. Examine each ",(0,s.jsx)(n.code,{children:"DATA_STREAM_SINK_OPERATOR"})," in the Execution Profile and check for abnormal ",(0,s.jsx)(n.code,{children:"RpcMaxTime"})," values. High RPC latency may indicate network issues."]}),"\n",(0,s.jsx)(n.h3,{id:"4-identify-high-cluster-load-issues",children:"4 Identify High Cluster Load Issues"}),"\n",(0,s.jsxs)(n.p,{children:["Doris's execution engine has a fixed number of execution threads. High cluster load can lead to tasks waiting for available workers. Analyze ",(0,s.jsx)(n.code,{children:"WaitWorkerTime"})," for each PipelineTask in the Execution Profile to assess cluster load."]})]})}function u(e={}){let{wrapper:n}={...(0,t.a)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},250065:function(e,n,i){i.d(n,{Z:function(){return a},a:function(){return o}});var r=i(667294);let s={},t=r.createContext(s);function o(e){let n=r.useContext(t);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),r.createElement(t.Provider,{value:n},e.children)}}}]);