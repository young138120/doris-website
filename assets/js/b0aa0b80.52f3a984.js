"use strict";(self.webpackChunkdoris_website=self.webpackChunkdoris_website||[]).push([["958060"],{677734:function(e,n,r){r.r(n),r.d(n,{metadata:()=>i,contentTitle:()=>t,default:()=>h,assets:()=>l,toc:()=>c,frontMatter:()=>o});var i=JSON.parse('{"id":"lakehouse/multi-catalog/hive","title":"Hive","description":"\x3c!--","source":"@site/versioned_docs/version-1.2/lakehouse/multi-catalog/hive.md","sourceDirName":"lakehouse/multi-catalog","slug":"/lakehouse/multi-catalog/hive","permalink":"/docs/1.2/lakehouse/multi-catalog/hive","draft":false,"unlisted":false,"tags":[],"version":"1.2","frontMatter":{"title":"Hive","language":"en"},"sidebar":"docs","previous":{"title":"Multi Catalog","permalink":"/docs/1.2/lakehouse/multi-catalog/"},"next":{"title":"Iceberg","permalink":"/docs/1.2/lakehouse/multi-catalog/iceberg"}}'),s=r("785893"),a=r("250065");let o={title:"Hive",language:"en"},t="Hive",l={},c=[{value:"Usage",id:"usage",level:2},{value:"Create Catalog",id:"create-catalog",level:2},{value:"Hive Versions",id:"hive-versions",level:3},{value:"Column Type Mapping",id:"column-type-mapping",level:2},{value:"Use Ranger for permission verification",id:"use-ranger-for-permission-verification",level:2},{value:"Environment configuration",id:"environment-configuration",level:3},{value:"Best Practices",id:"best-practices",level:3}];function d(e){let n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",version:"version",...(0,a.a)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"hive",children:"Hive"})}),"\n",(0,s.jsx)(n.p,{children:"Once Doris is connected to Hive Metastore or made compatible with Hive Metastore metadata service, it can access databases and tables in Hive and conduct queries."}),"\n",(0,s.jsx)(n.p,{children:"Besides Hive, many other systems, such as Iceberg and Hudi, use Hive Metastore to keep their metadata. Thus, Doris can also access these systems via Hive Catalog."}),"\n",(0,s.jsx)(n.h2,{id:"usage",children:"Usage"}),"\n",(0,s.jsx)(n.p,{children:"When connnecting to Hive, Doris:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["Need to put core-site.xml, hdfs-site.xml and hive-site.xml in the conf directory of FE and BE. First read the hadoop configuration file in the conf directory, and then read the related to the environment variable ",(0,s.jsx)(n.code,{children:"HADOOP_CONF_DIR"})," configuration file."]}),"\n",(0,s.jsx)(n.li,{children:"Supports Hive version 1/2/3;"}),"\n",(0,s.jsx)(n.li,{children:"Supports both Managed Table and External Table;"}),"\n",(0,s.jsx)(n.li,{children:"Can identify metadata of Hive, Iceberg, and Hudi stored in Hive Metastore;"}),"\n",(0,s.jsxs)(n.li,{children:["Supports Hive tables with data stored in JuiceFS, which can be used the same way as normal Hive tables (put ",(0,s.jsx)(n.code,{children:"juicefs-hadoop-x.x.x.jar"})," in ",(0,s.jsx)(n.code,{children:"fe/lib/"})," and ",(0,s.jsx)(n.code,{children:"apache_hdfs_broker/lib/"}),")."]}),"\n",(0,s.jsxs)(n.li,{children:["Supports Hive tables with data stored in CHDFS, which can be used the same way as normal Hive tables. Follow below steps to prepare doris environment\uFF1A\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"put chdfs_hadoop_plugin_network-x.x.jar in fe/lib/ and apache_hdfs_broker/lib/"}),"\n",(0,s.jsx)(n.li,{children:"copy core-site.xml and hdfs-site.xml from hive cluster to fe/conf/ and apache_hdfs_broker/conf"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.version,{since:"dev",children:["\n",(0,s.jsxs)(n.ol,{start:"7",children:["\n",(0,s.jsxs)(n.li,{children:["Supports Hive / Iceberg tables with data stored in GooseFS(GFS), which can be used the same way as normal Hive tables. Follow below steps to prepare doris environment\uFF1A\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"put goosefs-x.x.x-client.jar in fe/lib/ and apache_hdfs_broker/lib/"}),"\n",(0,s.jsx)(n.li,{children:"add extra properties 'fs.AbstractFileSystem.gfs.impl' = 'com.qcloud.cos.goosefs.hadoop.GooseFileSystem'\uFF0C 'fs.gfs.impl' = 'com.qcloud.cos.goosefs.hadoop.FileSystem' when creating catalog"}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.ol,{start:"8",children:["\n",(0,s.jsx)(n.li,{children:"If the Hadoop node is configured with hostname, please ensure to add the corresponding mapping relationship to the /etc/hosts file."}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"create-catalog",children:"Create Catalog"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"CREATE CATALOG hive PROPERTIES (\n    'type'='hms',\n    'hive.metastore.uris' = 'thrift://172.21.0.1:7004',\n    'hadoop.username' = 'hive',\n    'dfs.nameservices'='your-nameservice',\n    'dfs.ha.namenodes.your-nameservice'='nn1,nn2',\n    'dfs.namenode.rpc-address.your-nameservice.nn1'='172.21.0.2:4007',\n    'dfs.namenode.rpc-address.your-nameservice.nn2'='172.21.0.3:4007',\n    'dfs.client.failover.proxy.provider.your-nameservice'='org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider'\n);\n"})}),"\n",(0,s.jsxs)(n.p,{children:["In addition to ",(0,s.jsx)(n.code,{children:"type"})," and  ",(0,s.jsx)(n.code,{children:"hive.metastore.uris"})," , which are required, you can specify other parameters regarding the connection."]}),"\n",(0,s.jsx)(n.p,{children:"For example, to specify HDFS HA:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"CREATE CATALOG hive PROPERTIES (\n    'type'='hms',\n    'hive.metastore.uris' = 'thrift://172.21.0.1:7004',\n    'hadoop.username' = 'hive',\n    'dfs.nameservices'='your-nameservice',\n    'dfs.ha.namenodes.your-nameservice'='nn1,nn2',\n    'dfs.namenode.rpc-address.your-nameservice.nn1'='172.21.0.2:4007',\n    'dfs.namenode.rpc-address.your-nameservice.nn2'='172.21.0.3:4007',\n    'dfs.client.failover.proxy.provider.your-nameservice'='org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider'\n);\n"})}),"\n",(0,s.jsx)(n.p,{children:"To specify HDFS HA and Kerberos authentication information:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"CREATE CATALOG hive PROPERTIES (\n    'type'='hms',\n    'hive.metastore.uris' = 'thrift://172.21.0.1:7004',\n    'hive.metastore.sasl.enabled' = 'true',\n    'hive.metastore.kerberos.principal' = 'your-hms-principal',\n    'dfs.nameservices'='your-nameservice',\n    'dfs.namenode.rpc-address.your-nameservice.nn1'='172.21.0.2:4007',\n    'dfs.namenode.rpc-address.your-nameservice.nn2'='172.21.0.3:4007',\n    'dfs.client.failover.proxy.provider.your-nameservice'='org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider',\n    'hadoop.security.authentication' = 'kerberos',\n    'hadoop.kerberos.keytab' = '/your-keytab-filepath/your.keytab',   \n    'hadoop.kerberos.principal' = 'your-principal@YOUR.COM',\n    'yarn.resourcemanager.principal' = 'your-rm-principal'\n);\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Remember ",(0,s.jsx)(n.code,{children:"krb5.conf"})," and ",(0,s.jsx)(n.code,{children:"keytab"})," file should be placed at all ",(0,s.jsx)(n.code,{children:"BE"})," nodes and ",(0,s.jsx)(n.code,{children:"FE"})," nodes. The location of ",(0,s.jsx)(n.code,{children:"keytab"})," file should be equal to the value of ",(0,s.jsx)(n.code,{children:"hadoop.kerberos.keytab"}),".\nAs default, ",(0,s.jsx)(n.code,{children:"krb5.conf"})," should be placed at ",(0,s.jsx)(n.code,{children:"/etc/krb5.conf"}),"."]}),"\n",(0,s.jsxs)(n.p,{children:["Value of ",(0,s.jsx)(n.code,{children:"hive.metastore.kerberos.principal"})," should be same with the same name property used by HMS you are connecting to, which can be found in ",(0,s.jsx)(n.code,{children:"hive-site.xml"}),"."]}),"\n",(0,s.jsx)(n.p,{children:"To provide Hadoop KMS encrypted transmission information:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"CREATE CATALOG hive PROPERTIES (\n    'type'='hms',\n    'hive.metastore.uris' = 'thrift://172.21.0.1:7004',\n    'dfs.encryption.key.provider.uri' = 'kms://http@kms_host:kms_port/kms'\n);\n"})}),"\n",(0,s.jsx)(n.p,{children:"Or to connect to Hive data stored on JuiceFS:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"CREATE CATALOG hive PROPERTIES (\n    'type'='hms',\n    'hive.metastore.uris' = 'thrift://172.21.0.1:7004',\n    'hadoop.username' = 'root',\n    'fs.jfs.impl' = 'io.juicefs.JuiceFileSystem',\n    'fs.AbstractFileSystem.jfs.impl' = 'io.juicefs.JuiceFS',\n    'juicefs.meta' = 'xxx'\n);\n"})}),"\n",(0,s.jsx)(n.p,{children:"Or to connect to Glue and data stored on S3:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:'CREATE CATALOG hive PROPERTIES (\n    "type"="hms",\n    "hive.metastore.type" = "glue",\n    "aws.region" = "us-east-1",\n    "aws.glue.access-key" = "ak",\n    "aws.glue.secret-key" = "sk",\n    "AWS_ENDPOINT" = "s3.us-east-1.amazonaws.com",\n    "AWS_REGION" = "us-east-1",\n    "AWS_ACCESS_KEY" = "ak",\n    "AWS_SECRET_KEY" = "sk",\n    "use_path_style" = "true"\n);\n'})}),"\n",(0,s.jsx)(n.p,{children:"In Doris 1.2.1 and newer, you can create a Resource that contains all these parameters, and reuse the Resource when creating new Catalogs. Here is an example:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"# 1. Create Resource\nCREATE RESOURCE hms_resource PROPERTIES (\n    'type'='hms',\n    'hive.metastore.uris' = 'thrift://172.21.0.1:7004',\n    'hadoop.username' = 'hive',\n    'dfs.nameservices'='your-nameservice',\n    'dfs.ha.namenodes.your-nameservice'='nn1,nn2',\n    'dfs.namenode.rpc-address.your-nameservice.nn1'='172.21.0.2:4007',\n    'dfs.namenode.rpc-address.your-nameservice.nn2'='172.21.0.3:4007',\n    'dfs.client.failover.proxy.provider.your-nameservice'='org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider'\n);\n	\n# 2. Create Catalog and use an existing Resource. The key and value information in the followings will overwrite the corresponding information in the Resource.\nCREATE CATALOG hive WITH RESOURCE hms_resource PROPERTIES(\n    'key' = 'value'\n);\n"})}),"\n",(0,s.jsxs)(n.p,{children:["You can use the config ",(0,s.jsx)(n.code,{children:"file.meta.cache.ttl-second"})," to set TTL(Time-to-Live) config of File Cache, so that the stale file info will be invalidated automatically after expiring. The unit of time is second."]}),"\n",(0,s.jsx)(n.p,{children:"You can also set file_meta_cache_ttl_second to 0 to disable file cache.Here is an example:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"CREATE CATALOG hive PROPERTIES (\n    'type'='hms',\n    'hive.metastore.uris' = 'thrift://172.21.0.1:7004',\n    'hadoop.username' = 'hive',\n    'dfs.nameservices'='your-nameservice',\n    'dfs.ha.namenodes.your-nameservice'='nn1,nn2',\n    'dfs.namenode.rpc-address.your-nameservice.nn1'='172.21.0.2:4007',\n    'dfs.namenode.rpc-address.your-nameservice.nn2'='172.21.0.3:4007',\n    'dfs.client.failover.proxy.provider.your-nameservice'='org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider',\n    'file.meta.cache.ttl-second' = '60'\n);\n"})}),"\n",(0,s.jsxs)(n.p,{children:["You can also put the ",(0,s.jsx)(n.code,{children:"hive-site.xml"})," file in the ",(0,s.jsx)(n.code,{children:"conf"}),"  directories of FE and BE. This will enable Doris to automatically read information from ",(0,s.jsx)(n.code,{children:"hive-site.xml"}),". The relevant information will be overwritten based on the following rules :"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Information in Resource will overwrite that in  ",(0,s.jsx)(n.code,{children:"hive-site.xml"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:["Information in ",(0,s.jsx)(n.code,{children:"CREATE CATALOG PROPERTIES"})," will overwrite that in Resource."]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"hive-versions",children:"Hive Versions"}),"\n",(0,s.jsx)(n.p,{children:"Doris can access Hive Metastore in all Hive versions. By default, Doris uses the interface compatible with Hive 2.3 to access Hive Metastore. You can specify a certain Hive version when creating Catalogs, for example:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"CREATE CATALOG hive PROPERTIES (\n    'type'='hms',\n    'hive.metastore.uris' = 'thrift://172.21.0.1:7004',\n    'hive.version' = '1.1.0'\n);\n"})}),"\n",(0,s.jsx)(n.h2,{id:"column-type-mapping",children:"Column Type Mapping"}),"\n",(0,s.jsx)(n.p,{children:"This is applicable for Hive/Iceberge/Hudi."}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"HMS Type"}),(0,s.jsx)(n.th,{children:"Doris Type"}),(0,s.jsx)(n.th,{children:"Comment"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"boolean"}),(0,s.jsx)(n.td,{children:"boolean"}),(0,s.jsx)(n.td,{})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"tinyint"}),(0,s.jsx)(n.td,{children:"tinyint"}),(0,s.jsx)(n.td,{})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"smallint"}),(0,s.jsx)(n.td,{children:"smallint"}),(0,s.jsx)(n.td,{})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"int"}),(0,s.jsx)(n.td,{children:"int"}),(0,s.jsx)(n.td,{})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"bigint"}),(0,s.jsx)(n.td,{children:"bigint"}),(0,s.jsx)(n.td,{})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"date"}),(0,s.jsx)(n.td,{children:"date"}),(0,s.jsx)(n.td,{})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"timestamp"}),(0,s.jsx)(n.td,{children:"datetime"}),(0,s.jsx)(n.td,{})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"float"}),(0,s.jsx)(n.td,{children:"float"}),(0,s.jsx)(n.td,{})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"double"}),(0,s.jsx)(n.td,{children:"double"}),(0,s.jsx)(n.td,{})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"char"}),(0,s.jsx)(n.td,{children:"char"}),(0,s.jsx)(n.td,{})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"varchar"}),(0,s.jsx)(n.td,{children:"varchar"}),(0,s.jsx)(n.td,{})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"decimal"}),(0,s.jsx)(n.td,{children:"decimal"}),(0,s.jsx)(n.td,{})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"array<type>"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"array<type>"})}),(0,s.jsxs)(n.td,{children:["Support nested array, such as ",(0,s.jsx)(n.code,{children:"array<array<int>>"})]})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"map<KeyType, ValueType>"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"map<KeyType, ValueType>"})}),(0,s.jsx)(n.td,{children:"Not support nested map. KeyType and ValueType should be primitive types."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"struct<col1: Type1, col2: Type2, ...>"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"struct<col1: Type1, col2: Type2, ...>"})}),(0,s.jsx)(n.td,{children:"Not support nested struct. Type1, Type2, ... should be primitive types."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"other"}),(0,s.jsx)(n.td,{children:"unsupported"}),(0,s.jsx)(n.td,{})]})]})]}),"\n",(0,s.jsx)(n.h2,{id:"use-ranger-for-permission-verification",children:"Use Ranger for permission verification"}),"\n",(0,s.jsxs)(n.version,{since:"dev",children:["\n",(0,s.jsx)(n.p,{children:"Apache Ranger is a security framework for monitoring, enabling services, and managing comprehensive data security access on the Hadoop platform."}),"\n",(0,s.jsx)(n.p,{children:"Currently, Doris supports Ranger's library, table, and column permissions, but does not support encryption, row permissions, and so on."}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"environment-configuration",children:"Environment configuration"}),"\n",(0,s.jsx)(n.p,{children:"Connecting to Hive Metastore with Ranger permission verification enabled requires additional configuration&configuration environment:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"When creating a catalog, add:"}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:'"access_controller.properties.ranger.service.name" = "hive",\n"access_controller.class" = "org.apache.doris.catalog.authorizer.RangerHiveAccessControllerFactory",\n'})}),"\n",(0,s.jsxs)(n.ol,{start:"2",children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Configure all FE environments:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Copy the configuration files ranger-live-audit.xml, ranger-live-security.xml, ranger-policymgr-ssl.xml under the HMS conf directory to<doris_ Home>/conf directory."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Modify the properties of ranger-live-security.xml. The reference configuration is as follows:"}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:'<?xml version="1.0" encoding="UTF-8"?>\n<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>\n<configuration>\n    #The directory for caching permission data, needs to be writable\n    <property>\n        <name>ranger.plugin.hive.policy.cache.dir</name>\n        <value>/mnt/datadisk0/zhangdong/rangerdata</value>\n    </property>\n    #The time interval for periodically pulling permission data\n    <property>\n        <name>ranger.plugin.hive.policy.pollIntervalMs</name>\n        <value>30000</value>\n    </property>\n\n    <property>\n        <name>ranger.plugin.hive.policy.rest.client.connection.timeoutMs</name>\n        <value>60000</value>\n    </property>\n\n    <property>\n        <name>ranger.plugin.hive.policy.rest.client.read.timeoutMs</name>\n        <value>60000</value>\n    </property>\n\n    <property>\n        <name>ranger.plugin.hive.policy.rest.ssl.config.file</name>\n        <value></value>\n    </property>\n\n    <property>\n        <name>ranger.plugin.hive.policy.rest.url</name>\n        <value>http://172.21.0.32:6080</value>\n    </property>\n\n    <property>\n        <name>ranger.plugin.hive.policy.source.impl</name>\n        <value>org.apache.ranger.admin.client.RangerAdminRESTClient</value>\n    </property>\n\n    <property>\n        <name>ranger.plugin.hive.service.name</name>\n        <value>hive</value>\n    </property>\n\n    <property>\n        <name>xasecure.hive.update.xapolicies.on.grant.revoke</name>\n        <value>true</value>\n    </property>\n\n</configuration>\n'})}),"\n",(0,s.jsxs)(n.ol,{start:"3",children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"To obtain the log of Ranger authentication itself, you can click<doris_ Add the configuration file log4j.properties under the home>/conf directory."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Restart FE."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"best-practices",children:"Best Practices"}),"\n",(0,s.jsx)(n.p,{children:"1.Create user user1 on the ranger side and authorize the query permission of db1.table1.col1"}),"\n",(0,s.jsx)(n.p,{children:"2.Create the role role1 on the ranger side and authorize the query permission of db1.table1.col2"}),"\n",(0,s.jsx)(n.p,{children:"3.Create user user1 with the same name in Doris, and user1 will directly have the query permission of db1.table1.col1"}),"\n",(0,s.jsx)(n.p,{children:"4.Create the role role1 with the same name in Doris and assign role1 to user1. User1 will have query permissions for both db1.table1.col1 and col2"})]})}function h(e={}){let{wrapper:n}={...(0,a.a)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},250065:function(e,n,r){r.d(n,{Z:function(){return t},a:function(){return o}});var i=r(667294);let s={},a=i.createContext(s);function o(e){let n=i.useContext(a);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function t(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),i.createElement(a.Provider,{value:n},e.children)}}}]);